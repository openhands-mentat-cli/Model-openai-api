# Core dependencies for llama.cpp with optimizations
# Use a more stable version that builds reliably
llama-cpp-python[server]==0.2.28
fastapi==0.110.0
uvicorn[standard]==0.27.1
pydantic==2.6.1
requests==2.31.0
huggingface-hub==0.20.3

# Build dependencies to ensure compilation works
cmake>=3.22.0
scikit-build-core>=0.5.0

# Additional useful dependencies
typing-extensions>=4.0.0
